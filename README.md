# Machine Learning Algos

Welcome to the **Machine Learning Algos** repository!  
This repo contains a hands-on, categorized collection of essential machine learning algorithms and foundational concepts, neatly organized into **Supervised**, **Unsupervised**, and **Data Preprocessing** sections.

Each topic includes concise code implementations, core logic explanations, and visual insights wherever helpful â€” great for both beginners and those revising ML fundamentals.

---

## Supervised Learning

Supervised learning algorithms train on input-output pairs (features + target). The goal is to learn a function that maps inputs to desired outputs.

- **Multiple Regression**  
  Predicts a continuous output based on multiple input features using a linear relationship.

- **Decision Tree**  
  A tree-like model for classification or regression. Splits data based on feature thresholds to make decisions.

- **Confusion Matrix**  
  A performance evaluation tool for classification problems. Shows true vs. predicted class counts.

- **Logistic Regression**  
  A classification algorithm that models the probability of a class using the logistic function.

- **K-Nearest Neighbors (KNN)**  
  A non-parametric method that classifies data points based on the majority class of their k closest neighbors.

- **Cross Validation**  
  A resampling technique (like K-Fold) used to evaluate model performance and reduce overfitting risk.

- **Grid Search**  
  Automates hyperparameter tuning by trying all combinations and selecting the best-performing set.

- **Train or Test Split**  
  Splits data into training and test sets to evaluate how well a model generalizes to unseen data.

- **Bootstrap Aggregation (Bagging)**  
  An ensemble technique that combines multiple models trained on random subsets to reduce variance.

---

## Unsupervised Learning

Unsupervised learning works with data that has **no labels**. It attempts to find hidden structure or patterns.

- **Hierarchical Clustering**  
  Builds a tree of clusters using either agglomerative (bottom-up) or divisive (top-down) approaches.

- **K-Means Clustering**  
  Partitions data into **k** clusters based on distance to cluster centroids. Common for grouping or pattern discovery.

---

## Miscellaneous / Data Preprocessing / Statistics

These are essential building blocks for preparing, cleaning, and understanding your data:

- **Mean, Median, and Mode**  
  Measures of central tendency for summarizing numerical data.

- **Percentiles**  
  Indicators of the relative standing of a value within a dataset. Helpful for outlier detection.

- **Data Distribution**  
  Visual or statistical representation of how data values are spread out.

- **Normal Data Distribution**  
  A special bell-shaped distribution where most values cluster around the mean.

- **Scaling**  
  Techniques like **Standardization** and **Normalization** to ensure features contribute equally to the model.

- **Categorical Data Encoding**  
  Converting text labels into numerical format using **Label Encoding** or **One-Hot Encoding** for ML compatibility.

---

## Goals

- Help learners understand core ML algorithms step-by-step  
- Create a reusable foundation for ML-based projects  
- Make machine learning more accessible through clean, commented code

---
